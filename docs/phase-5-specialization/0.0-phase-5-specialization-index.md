# Phase 5: Specialization

This is the deep end. You've built systems that work - now you're learning to build systems that work *better* for specific domains.

## The Big Picture

Most AI applications can get pretty far with general-purpose models and techniques. But there comes a point where "pretty good" isn't enough. Maybe your legal domain searches keep missing relevant cases because the model doesn't understand legal terminology. Maybe your medical chatbot needs to be more reliable than a general-purpose model can guarantee. Maybe you need to process images alongside text.

That's when you reach for specialization techniques.

The key insight I had while exploring this phase: **specialization is usually the last resort, not the first**. These techniques are powerful, but they come with costs - training time, data requirements, maintenance burden. The hierarchy is clear:

1. First, try better prompts
2. Then, add RAG for knowledge
3. Only then, consider fine-tuning

But when you do need these techniques, they unlock capabilities that weren't possible before.

## What's Here

### Fine-tuning LLMs

When you have 500+ high-quality examples and need consistent behavior, fine-tuning becomes viable. This module covers:
- When fine-tuning actually makes sense (spoiler: less often than you'd think)
- LoRA and QLoRA - how to fine-tune 7B models on a consumer GPU
- Data preparation - the most important and most neglected part
- Alignment techniques like DPO

### Custom Embeddings

OpenAI's embeddings are excellent for general use. But if you're building a legal search system and "tort" needs to be closer to "liability" than to "cake", you might need domain-adapted embeddings. This module covers:
- Running Sentence Transformers locally (free, fast, private)
- TSDAE for unsupervised domain adaptation
- How to actually evaluate if your embeddings are better

### Advanced NLP

Sometimes you need more structure than "throw it at GPT-4". Dependency parsing, relation extraction, coreference resolution - these traditional NLP techniques are fast, precise, and free. The module covers when to use them versus when to just use an LLM.

### Multimodal

Text isn't everything. GPT-4V can analyze images. CLIP can search images with text queries. Document vision can extract invoices and forms. This module shows how to work with both text and images together.

## Why "Specialization"?

I called this phase specialization because that's what it is - you're moving from general-purpose solutions to ones optimized for specific use cases. It's not necessary for every project. But when you need it, it's transformative.

For the job market analyzer, specialization might mean:
- Fine-tuning a classifier on job categories when GPT-4's zero-shot classification isn't consistent enough
- Domain-adapting embeddings to understand "ML engineer" vs "AI researcher" nuances
- Using CLIP to search job posts that include company logos or team photos

## Before You Dive In

Make sure you're comfortable with everything in Phases 1-4. Specialization builds on those foundations. If your RAG pipeline isn't working well, fine-tuning won't fix it - better prompts and retrieval probably will.

## Modules

| Module | What it covers |
|--------|----------------|
| [Fine-tuning](./5.1-fine-tuning.md) | When and how to train custom models |
| [Custom Embeddings](./5.2-custom-embeddings.md) | Local embeddings and domain adaptation |
| [Advanced NLP](./5.3-advanced-nlp.md) | Structured extraction with traditional techniques |
| [Multimodal](./5.4-multimodal.md) | Working with images and text together |
