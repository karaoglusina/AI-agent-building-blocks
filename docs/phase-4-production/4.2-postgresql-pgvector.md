# PostgreSQL + pgvector

ChromaDB is great for learning and small-scale use. For production, you want a database you trust with your data. PostgreSQL with pgvector gives you vector search in a battle-tested database.

## Why This Matters

PostgreSQL has been reliable for decades. Adding pgvector means you get vector search with ACID transactions, proper backups, replication, and the full SQL ecosystem. One database for everything.

For our job market analyzer, this means storing job data and embeddings in the same database, with joins, transactions, and all the reliability of PostgreSQL.

## The Key Ideas

### pgvector Extension

Enable vector operations in PostgreSQL:

```sql
CREATE EXTENSION vector;

CREATE TABLE documents (
  id SERIAL PRIMARY KEY,
  content TEXT,
  embedding VECTOR(1536)  -- OpenAI embedding size
);
```

Now you can store and search vectors.

### Vector Operations

```sql
-- Find similar documents (cosine distance)
SELECT * FROM documents
ORDER BY embedding <=> '[0.1, 0.2, ...]'
LIMIT 5;

-- With distance threshold
SELECT * FROM documents
WHERE embedding <=> query_embedding < 0.5
ORDER BY embedding <=> query_embedding;
```

`<=>` is cosine distance. Lower = more similar.

### SQLAlchemy Integration

```python
from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
from pgvector.sqlalchemy import Vector

class Document(Base):
    __tablename__ = "documents"
    id: Mapped[int] = mapped_column(primary_key=True)
    content: Mapped[str]
    embedding: Mapped[Vector] = mapped_column(Vector(1536))
```

Works with your existing SQLAlchemy knowledge.

### Vector Search in Python

```python
# Find similar documents
results = session.execute(
    select(Document)
    .order_by(Document.embedding.cosine_distance(query_embedding))
    .limit(5)
).scalars().all()
```

### Indexes

For large datasets, add an index:

```sql
-- IVFFlat: Good for 10k-1M vectors
CREATE INDEX ON documents
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- HNSW: Better accuracy, faster queries
CREATE INDEX ON documents
USING hnsw (embedding vector_cosine_ops);
```

### Hybrid Search

Combine full-text and vector search:

```python
# Vector similarity
vector_results = vector_search(query)

# Keyword matching
keyword_results = full_text_search(query)

# Combine
combined = reciprocal_rank_fusion(vector_results, keyword_results)
```

## What's in This Module

| Script | What it shows |
|--------|---------------|
| [01_sqlalchemy_basics.py](../../modules/Phase 4 - Production Systems/4.2-postgresql-pgvector/01_sqlalchemy_basics.py) | Define models, create tables |
| [02_crud_operations.py](../../modules/Phase 4 - Production Systems/4.2-postgresql-pgvector/02_crud_operations.py) | Create, read, update, delete |
| [03_alembic_migrations.py](../../modules/Phase 4 - Production Systems/4.2-postgresql-pgvector/03_alembic_migrations.py) | Database schema versioning |
| [04_pgvector_setup.py](../../modules/Phase 4 - Production Systems/4.2-postgresql-pgvector/04_pgvector_setup.py) | Enable vector extension |
| [05_vector_search_pg.py](../../modules/Phase 4 - Production Systems/4.2-postgresql-pgvector/05_vector_search_pg.py) | Semantic search |
| [06_hybrid_pg.py](../../modules/Phase 4 - Production Systems/4.2-postgresql-pgvector/06_hybrid_pg.py) | Full-text + vector search |

## Setup

```bash
# Run PostgreSQL with pgvector (Docker)
docker run -d \
  --name postgres-pgvector \
  -p 5432:5432 \
  -e POSTGRES_PASSWORD=postgres \
  ankane/pgvector

# Install Python packages
pip install sqlalchemy psycopg2-binary pgvector alembic
```

## pgvector vs ChromaDB

| Feature | pgvector | ChromaDB |
|---------|----------|----------|
| Setup | Extension on PostgreSQL | Separate service |
| Transactions | ACID compliant | Eventually consistent |
| SQL Features | Full SQL | Limited queries |
| Scalability | TB scale | GB scale |
| Production Use | Battle-tested | Newer |
| Best For | Production apps | Prototyping |

## Best Practices

### Index After Bulk Insert
```sql
-- Drop index before bulk insert
DROP INDEX IF EXISTS documents_embedding_idx;

-- Bulk insert your data
-- ...

-- Create index after
CREATE INDEX documents_embedding_idx ON documents
USING ivfflat (embedding vector_cosine_ops) WITH (lists = 100);
```

### Connection Pooling
```python
engine = create_engine(
    DATABASE_URL,
    pool_size=20,
    max_overflow=10
)
```

### Analyze Tables
```sql
ANALYZE documents;  -- Update statistics for query planner
```

## Things to Think About

- **When do you need pgvector over ChromaDB?** When you need transactions, joins with relational data, or production reliability.
- **How many vectors can it handle?** Millions with proper indexing. For billions, consider specialized vector databases.
- **What about cloud hosting?** AWS RDS, Google Cloud SQL, and others support pgvector.

## Related

- [Vector Search](../phase-1-foundations/1.6-vector-search.md) - ChromaDB basics
- [Docker](./4.1-docker.md) - Running PostgreSQL in containers
- [Advanced RAG](../phase-3-advanced-patterns/3.4-advanced-rag.md) - Hybrid search patterns

## Book References

- AI_eng.6 - Vector databases
