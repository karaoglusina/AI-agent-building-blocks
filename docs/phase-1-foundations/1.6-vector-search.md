# Vector Search

Embeddings let you represent meaning as vectors. But when you have 10,000 job postings, storing them in a numpy array and doing linear search isn't practical. You need a database that understands vectors.

## Why This Matters

ChromaDB (and similar tools) handle the mechanics of storing, indexing, and searching embeddings. They also add features you'll need: persistence, metadata filtering, and CRUD operations.

For our job market analyzer, this is how we make 10k+ job postings searchable in milliseconds.

## The Key Ideas

### ChromaDB Basics

```python
import chromadb

# Create client (in-memory for testing)
client = chromadb.Client()

# Create a collection (like a table)
collection = client.create_collection("jobs")

# Add documents
collection.add(
    documents=["ML engineer role at startup...", "Data scientist position..."],
    ids=["job1", "job2"],
    metadatas=[{"company": "Acme"}, {"company": "TechCorp"}]
)

# Search
results = collection.query(
    query_texts=["remote machine learning"],
    n_results=5
)
```

That's the core workflow: create collection, add documents, query.

### Persistence

In-memory is fine for experimentation. For real use, persist to disk:

```python
# This saves to ./chroma_data
client = chromadb.PersistentClient(path="./chroma_data")

# Collections survive restarts
collection = client.get_or_create_collection("jobs")
```

### Metadata Filtering

Combine semantic search with structured filters:

```python
results = collection.query(
    query_texts=["machine learning"],
    n_results=10,
    where={"location": "remote"}  # Only remote jobs
)
```

Filter first, then rank by similarity. This is how you answer "remote ML jobs in Europe" - filter on metadata (remote, Europe), rank by embedding similarity (ML).

### Custom Embeddings

By default, ChromaDB uses its own embedding model. For consistency with your other code, use OpenAI:

```python
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction

embedding_fn = OpenAIEmbeddingFunction(
    api_key="...",
    model_name="text-embedding-3-small"
)

collection = client.create_collection(
    name="jobs",
    embedding_function=embedding_fn
)
```

Now queries and documents use the same embedding model.

### CRUD Operations

Real applications need more than add and query:

```python
# Update metadata
collection.update(
    ids=["job1"],
    metadatas=[{"company": "NewName", "status": "filled"}]
)

# Delete
collection.delete(ids=["job1"])

# Get specific documents
docs = collection.get(ids=["job1", "job2"])
```

## What's in This Module

| Script | What it shows |
|--------|---------------|
| [01_chroma_basics.py](../../modules/Phase%201%20-%20Foundations/1.6-vector-search/01_chroma_basics.py) | Basic add and query operations |
| [02_persistent_storage.py](../../modules/Phase%201%20-%20Foundations/1.6-vector-search/02_persistent_storage.py) | Save collections to disk |
| [03_metadata_filtering.py](../../modules/Phase%201%20-%20Foundations/1.6-vector-search/03_metadata_filtering.py) | Filter results by metadata |
| [04_openai_embeddings.py](../../modules/Phase%201%20-%20Foundations/1.6-vector-search/04_openai_embeddings.py) | Use OpenAI embeddings with ChromaDB |
| [05_job_database.py](../../modules/Phase%201%20-%20Foundations/1.6-vector-search/05_job_database.py) | Build a searchable job database |
| [06_crud_operations.py](../../modules/Phase%201%20-%20Foundations/1.6-vector-search/06_crud_operations.py) | Create, Read, Update, Delete operations |

## When to Use What

| Approach | Use When |
|----------|----------|
| Numpy arrays | <10k docs, prototyping, no persistence needed |
| ChromaDB | >10k docs, need persistence, need filtering, local deployment |
| Pinecone/Weaviate | Millions of docs, managed service, production scale |
| pgvector | Already using PostgreSQL, want one database for everything |

ChromaDB is the sweet spot for learning and small-to-medium production use.

## Things to Think About

- **What happens when you add duplicate IDs?** ChromaDB updates the existing record. Be careful with your ID strategy.
- **How do you handle document updates?** Delete and re-add, or use update(). Both work.
- **When do you need something more than ChromaDB?** Millions of documents, complex query requirements, or when you need a managed service.

## Related

- [Embeddings](./1.5-embeddings.md) - Understanding what you're storing
- [RAG Pipeline](../phase-2-building-ai-systems/2.4-rag-pipeline.md) - Using vector search in retrieval
- [PostgreSQL + pgvector](../phase-4-production/4.2-postgresql-pgvector.md) - Production-grade vector storage

## Book References

- hands_on_LLM.II.8 - Retrieval systems
- AI_eng.6 - RAG architecture
