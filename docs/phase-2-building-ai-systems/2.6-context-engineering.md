# Context Engineering

LLMs have limited context windows. Even with 128k tokens, you can't fit everything. Context engineering is about deciding what to include, how to format it, and how to make the most of limited space.

## Why This Matters

When you're doing RAG with dozens of documents, maintaining conversation history, and including tool outputs, you hit limits. What do you keep? What do you cut? These decisions directly affect output quality.

For our job market analyzer, context engineering determines which job postings to include when answering a question, how much conversation history to maintain, and how to structure the prompt for best results.

## The Key Ideas

### Token Budgets

Think of context as a budget you allocate:

```
┌────────────────────────────────────────┐
│          Context Window                 │
├────────────────────────────────────────┤
│ System Prompt          │  ~200 tokens  │
│ Retrieved Documents    │ ~2000 tokens  │
│ Conversation History   │ ~1000 tokens  │
│ User Query             │  ~100 tokens  │
│ Reserved for Response  │  ~500 tokens  │
├────────────────────────────────────────┤
│ Total Used             │ ~3800 tokens  │
└────────────────────────────────────────┘
```

Count tokens with tiktoken:

```python
import tiktoken
enc = tiktoken.encoding_for_model("gpt-4o-mini")
token_count = len(enc.encode(text))
```

### Prompt Assembly

Build prompts modularly:

```python
def assemble_prompt(query, context, history, preferences):
    parts = []

    # System prompt
    parts.append(SYSTEM_PROMPT)

    # User preferences (if any)
    if preferences:
        parts.append(f"User preferences: {preferences}")

    # Retrieved context
    if context:
        parts.append(f"Relevant information:\n{context}")

    # Recent history
    if history:
        parts.append(f"Recent conversation:\n{format_history(history)}")

    # Current query
    parts.append(f"User query: {query}")

    return "\n\n".join(parts)
```

Each piece can be independently sized and formatted.

### Context Prioritization

When space is limited, prioritize:

```python
def prioritize_documents(docs, query, max_tokens=2000):
    # Score by relevance
    scored = [(doc, relevance_score(doc, query)) for doc in docs]
    scored.sort(key=lambda x: -x[1])

    # Take docs until budget exhausted
    selected = []
    tokens_used = 0
    for doc, score in scored:
        doc_tokens = count_tokens(doc)
        if tokens_used + doc_tokens > max_tokens:
            break
        selected.append(doc)
        tokens_used += doc_tokens

    return selected
```

Most relevant first, cut from the bottom.

### Context Compression

When you need more information than fits, compress:

```python
def compress_context(documents, query):
    # Use LLM to extract key information
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{
            "role": "user",
            "content": f"Extract key facts relevant to '{query}' from:\n{documents}"
        }]
    )
    return response.choices[0].message.content
```

Compression loses detail but fits more information. Use when breadth matters more than depth.

### Dynamic System Prompts

System prompts don't have to be static:

```python
def get_system_prompt(task_type, user_preferences):
    base = "You are a job market analyst."

    if task_type == "search":
        base += " Focus on finding relevant job postings."
    elif task_type == "compare":
        base += " Analyze differences between options."

    if user_preferences.get("prefers_remote"):
        base += " The user prefers remote positions."

    return base
```

Adapt the system prompt to the current context.

## What's in This Module

| Script | What it shows |
|--------|---------------|
| [01_context_window_basics.py](../../modules/Phase 2 - Building AI Systems/2.6-context-engineering/01_context_window_basics.py) | Understanding token limits |
| [02_prompt_assembly.py](../../modules/Phase 2 - Building AI Systems/2.6-context-engineering/02_prompt_assembly.py) | Building prompts from components |
| [03_context_prioritization.py](../../modules/Phase 2 - Building AI Systems/2.6-context-engineering/03_context_prioritization.py) | Selecting what to include |
| [04_context_compression.py](../../modules/Phase 2 - Building AI Systems/2.6-context-engineering/04_context_compression.py) | Fitting more in less space |
| [05_dynamic_system_prompts.py](../../modules/Phase 2 - Building AI Systems/2.6-context-engineering/05_dynamic_system_prompts.py) | Adapting system prompts |

## Strategies

| Strategy | When to Use | Trade-off |
|----------|-------------|-----------|
| Prioritization | Have many docs, need best ones | May miss relevant info |
| Compression | Need breadth over depth | Loses detail |
| Chunking | Very long documents | Loses cross-chunk context |
| Dynamic prompts | Multi-task system | Added complexity |

## Things to Think About

- **How do you know what's most relevant?** Embedding similarity is a start. But recency, user preferences, and source authority matter too.
- **When does compression hurt more than help?** When details matter. Compressing "salary is $150,000" to "high salary" loses useful information.
- **What's the minimum context for good output?** Depends on the task. Experiment to find the right balance.

## Related

- [RAG Pipeline](./2.4-rag-pipeline.md) - Managing retrieval context
- [Memory Patterns](./2.7-memory-patterns.md) - Conversation history in context
- [Conversations](../phase-1-foundations/1.4-conversations.md) - Basic conversation context

## Book References

- AI_eng.5 - Prompt engineering
- AI_eng.6 - RAG context management
- hands_on_LLM.I.3 - Token economics
