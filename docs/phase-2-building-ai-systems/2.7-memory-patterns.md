# Memory Patterns

LLMs don't remember between calls. Every request is independent. Memory patterns give your agents continuity - the ability to remember what happened before, what the user prefers, and what was discussed.

## Why This Matters

Without memory, every conversation starts fresh. The user says "I prefer remote jobs" and two messages later, you've forgotten. Memory makes interactions feel coherent and personalized.

For our job market analyzer, memory means remembering search preferences, tracking entities mentioned ("the second job", "the Amsterdam position"), and maintaining context across a session.

## The Key Ideas

### Conversation Buffer

The simplest approach: store all messages.

```python
class ConversationBuffer:
    def __init__(self):
        self.messages = []

    def add(self, role: str, content: str):
        self.messages.append({"role": role, "content": content})

    def get_messages(self):
        return self.messages
```

Works for short conversations. Grows unbounded - eventually hits context limits.

### Sliding Window

Keep only the most recent N messages:

```python
class SlidingWindow:
    def __init__(self, window_size: int = 10):
        self.messages = []
        self.window_size = window_size

    def add(self, role: str, content: str):
        self.messages.append({"role": role, "content": content})
        if len(self.messages) > self.window_size:
            self.messages.pop(0)
```

Bounded memory. Loses old context, but stays within limits.

### Summary Memory

Compress old messages instead of deleting them:

```python
class SummaryMemory:
    def __init__(self):
        self.summary = ""
        self.recent_messages = []

    def compress_if_needed(self):
        if len(self.recent_messages) > 10:
            # Summarize older messages
            old_messages = self.recent_messages[:-5]
            new_summary = summarize(self.summary, old_messages)
            self.summary = new_summary
            self.recent_messages = self.recent_messages[-5:]
```

Preserves important information while staying bounded.

### Entity Memory

Track specific entities mentioned in conversation:

```python
class EntityMemory:
    def __init__(self):
        self.entities = {}  # name -> info

    def update(self, message: str):
        # Extract entities from message
        extracted = extract_entities(message)
        for entity, info in extracted.items():
            if entity in self.entities:
                self.entities[entity].update(info)
            else:
                self.entities[entity] = info

# "The job at Google" -> entities["Google"] = {type: "company", context: "job posting"}
```

Enables references like "tell me more about the Google position."

### Long-Term Storage

Some information should persist across sessions:

```python
class LongTermMemory:
    def __init__(self, db_path: str):
        self.db = connect(db_path)

    def store(self, key: str, value: str, importance: float):
        self.db.save(key, value, importance, timestamp=now())

    def retrieve(self, query: str, top_k: int = 5):
        # Use embeddings to find relevant memories
        return self.db.semantic_search(query, top_k)
```

User preferences, important facts - things that matter across sessions.

### Memory Retrieval

For large memory stores, retrieve relevant memories:

```python
def get_relevant_context(query: str, memory_store):
    # Embed the current query
    # Find similar memories
    # Include in context
    relevant = memory_store.search(query, top_k=5)
    return format_memories(relevant)
```

Don't include all memories - include the relevant ones.

## What's in This Module

| Script | What it shows |
|--------|---------------|
| [01_conversation_buffer.py](../../modules/Phase 2 - Building AI Systems/2.7-memory-patterns/01_conversation_buffer.py) | Simple full-history storage |
| [02_sliding_window.py](../../modules/Phase 2 - Building AI Systems/2.7-memory-patterns/02_sliding_window.py) | Bounded recent history |
| [03_summary_memory.py](../../modules/Phase 2 - Building AI Systems/2.7-memory-patterns/03_summary_memory.py) | Compress old messages |
| [04_entity_memory.py](../../modules/Phase 2 - Building AI Systems/2.7-memory-patterns/04_entity_memory.py) | Track entities in conversation |
| [05_long_term_storage.py](../../modules/Phase 2 - Building AI Systems/2.7-memory-patterns/05_long_term_storage.py) | Persist across sessions |
| [06_memory_retrieval.py](../../modules/Phase 2 - Building AI Systems/2.7-memory-patterns/06_memory_retrieval.py) | Semantic memory retrieval |

## Comparing Patterns

| Pattern | Capacity | Fidelity | Speed | Use Case |
|---------|----------|----------|-------|----------|
| Buffer | Unbounded | Perfect | Fast | Short chats |
| Window | Fixed | Recent only | Fast | Long sessions |
| Summary | Compressed | Good | Medium | Long conversations |
| Entity | Key facts | Selected | Medium | Personalization |
| Long-term | Persistent | Selected | Medium | Cross-session |
| Retrieval | Large | Relevant | Slower | Knowledge-heavy |

## Things to Think About

- **What's worth remembering?** Not everything. User preferences, important decisions, key facts - yes. Casual chit-chat - probably not.
- **How do you handle contradictions?** User says "I prefer remote" then later "actually, I'd consider office roles." Memory needs update mechanisms.
- **When do you surface memories?** Retrieve relevant ones based on current context. Don't dump everything into every prompt.

## Related

- [Conversations](../phase-1-foundations/1.4-conversations.md) - Basic conversation handling
- [Context Engineering](./2.6-context-engineering.md) - Memory as part of context
- [Agent Orchestration](./2.5-agent-orchestration.md) - Agents with memory
- [Advanced Memory](../phase-3-advanced-patterns/3.3-advanced-memory.md) - More sophisticated patterns

## Book References

- AI_eng.6 - Agent memory patterns
- hands_on_LLM.II.7 - Conversation management
- speach_lang.III.23 - Entity tracking
